# ğŸ“š WikiSearchEngine: A Java Web Crawler with TF-IDF & Cosine Similarity

This Java application crawls Wikipedia pages starting from two predefined URLs, builds an **inverted index**, and allows querying the crawled content using **TF-IDF** and **cosine similarity** ranking.

---

## ğŸš€ Features

- ğŸ”— Crawls up to **20 distinct Wikipedia pages** starting from two given seed URLs.
- ğŸ§¹ Extracts and **cleans textual content**, then builds an inverted index (term â [docID, frequency]).
- ğŸ“Š Computes **TF-IDF scores** for terms in each document.
- ğŸ” Accepts a **user query**, applies the same TF-IDF weighting, and computes **cosine similarity** with each document.
- ğŸ† Returns the **Top 10 most relevant documents** sorted by similarity score.

---

## ğŸ”§ Technologies

- **Java 8+**
- **Maven**
- **[Jsoup](https://jsoup.org/)** for HTML parsing

---

## ğŸ—‚ï¸ Project Structure

```
webcrawler-tfidf/
â”œâ”€â”€ pom.xml                         # Project dependencies (Jsoup)
â”œâ”€â”€ README.md                       # Project overview and instructions
â”œâ”€â”€ report/
â”‚   â””â”€â”€ Report.pdf                  # Design & explanation
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â””â”€â”€ java/
â”‚           â””â”€â”€ com/
â”‚               â””â”€â”€ tfidf/
â”‚                   â”œâ”€â”€ Main.java
â”‚                   â”œâ”€â”€ crawler/
â”‚                   â”‚   â””â”€â”€ WebCrawler.java
â”‚                   â”œâ”€â”€ text/
â”‚                   â”‚   â””â”€â”€ Normalizer.java
â”‚                   â”œâ”€â”€ index/
â”‚                   â”‚   â”œâ”€â”€ InvertedIndex.java
â”‚                   â”‚   â””â”€â”€ Posting.java
â”‚                   â”œâ”€â”€ ranking/
â”‚                   â”‚   â”œâ”€â”€ TFIDFCalculator.java
â”‚                   â”‚   â”œâ”€â”€ CosineSimilarity.java
â”‚                   â”‚   â”œâ”€â”€ DocumentTFIDF.java
â”‚                   â”‚   â””â”€â”€ Ranker.java
```

---

## ğŸ‘¥ Team Responsibilities

| Module                       | Description                                                         | Team Members         |
|-----------------------------|---------------------------------------------------------------------|----------------------|
| Web Crawling                | Crawl Wikipedia, avoid duplicates, restrict domain                 | Amany, Israa         |
| Text Normalization & Index  | Tokenization, normalization, inverted index construction           | Joseph, Yousef       |
| TF-IDF & Ranking            | Compute TF-IDF weights, cosine similarity, and rank documents      | Salma, Jonathan      |
| Documentation & Comments    | Code documentation, final report                                   | Whole Team           |

---

## ğŸ› ï¸ How to Run the Program

### ğŸ§± Prerequisites

- Java 8 or later
- Maven installed

### ğŸ“¦ Setup and Build

1. Clone the repository:
   ```bash
   git clone https://github.com/IsraaXx/WikiSearchEngine.git
   cd WikiSearchEngine
   ```

2. Add **Jsoup** dependency to `pom.xml`:
   ```xml
   <dependency>
       <groupId>org.jsoup</groupId>
       <artifactId>jsoup</artifactId>
       <version>1.15.3</version>
   </dependency>
   ```

3. Build and run:
   ```bash
   mvn clean install
   mvn exec:java -Dexec.mainClass="com.tfidf.Main"
   ```

4. When prompted, **enter your search query** and get ranked results based on relevance.

---

## ğŸ“‘ Deliverables

- âœ… Fully working Java application with crawling, indexing, and search functionality.
- ğŸ“„ Report explaining the design of each module.
- âŒ No need for extra user manual or presentation files.

---

## ğŸ§  Concepts Used

- **Web Crawling** with domain restrictions and deduplication.
- **Text Normalization** (tokenization, case folding).
- **Inverted Index** structure.
- **TF-IDF Weighting**:
  - TF = 1 + log10(term frequency)
  - IDF = log10(N / df(term))
- **Cosine Similarity** to compare the user query with document vectors.

---

## ğŸ’¡ Example Query Flow

```
User enters: ancient egypt king
â†’ Query vector computed
â†’ Cosine similarity calculated with each of the 10 documents
â†’ Top 10 relevant Wikipedia pages printed (ranked)
```

---

## ğŸ§ª Testing Tips

- Use sample queries like: `pharaoh`, `egypt`, `dynasty`, `history`.
- Check if duplicate Wikipedia pages are skipped during crawling.
- Validate inverted index by printing terms and posting lists.

---

## ğŸ“¬ Contact

This project was built as part of **Assignment 2 - Web Crawler with TF-IDF** at Cairo University.

---

> ğŸ’¬ â€œThe best search engine is the one you build yourself.â€
